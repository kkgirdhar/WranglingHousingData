{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code to find the python version\n",
    "import platform \n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the .dat file, it was opened and examined in Visual code to have a look at the contents and format of the file. We found that the file consisted of {,[ which is very likely to be JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parsing the data.dat file\n",
    "with open(\"data.dat\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "print type(json_data)\n",
    "#json_data['meta']['view']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Viewing the first record of the file.\n",
    "json_data['houses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting the JSON object into the data frame usong the json_normalize\n",
    "df = json_normalize(json_data['houses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#looking into the normalize data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataframe __`df`__ above has following issues that must be fixed to meet the requirement of the task:\n",
    "1. `address` is a composite attribute that needs to be sub-divied into street, city, statezip, and country.\n",
    "2. `rooms` is a composite attribute that needs to be sub-divided into bedrooms and bathrooms. \n",
    "3. `sqft_living` and `sqft_lot` are in one column. It must be separated into 2 columns.\n",
    "4. Check and change data types of columns where required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the address column into street, city , statezip and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ref :https://stackoverflow.com/questions/14745022/pandas-dataframe-how-do-i-split-a-column-into-two ;, by LeoRochel\n",
    "# the following code splits the column into 4  columns and add the new columns on the dataframe\n",
    "df = df.join(df['address'].str.split(',', 3, expand=True).rename(columns={0:'street', 1:'city', 2:'statezip', 3:'country'}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command has worked perfectly and the address has been split into different columns and added on to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the room column\n",
    "The below code will split the room column into bedrooms and bathrooms and add the new column into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/14745022/pandas-dataframe-how-do-i-split-a-column-into-two ;, by LeoRochel\n",
    "\n",
    "df = df.join(df['rooms'].str.split(';', 2, expand=True).rename(columns={0:'bathrooms', 1:'bedrooms'}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command has worked perfectly and the new columns bathrooms and bedrooms has been added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the consistency of the newly added columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks for the newly added column bathrooms, if all the values starts with \"Number of bathrooms \" and no value starts with \"Number of bedrooms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['checkbath'] = df['bathrooms'].apply(lambda value: value.startswith('Number of bedrooms'))\n",
    "len(df[df[\"checkbath\"] == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command adds a new column in the checkbath and stores the boolean value. It is seen that there are 400 rows that contains the bedrooms value in the bathroom column. Lets check the same for the bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['checkbed'] = df['bedrooms'].apply(lambda value: value.startswith(' Number of bathrooms'))\n",
    "len(df[df[\"checkbed\"] == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bedrooms column contians 400 values of the bathrooms. Now lets check if all these values for bedrooms and bathroom have been reversly added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the following code gets the index of all the bathrooms that have bedrooms value\n",
    "idx_checkbath = (df[df[\"checkbath\"] == True]).index.tolist()\n",
    "\n",
    "len(idx_checkbath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the following code gets the index of all the bedrooms that have bathrooms value\n",
    "idx_checkbed = (df[df[\"checkbed\"] == True]).index.tolist()\n",
    "\n",
    "len(idx_checkbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#it checks if the values of subset of  bedrooms and bathrooms that has been reversed are same \n",
    "if(idx_checkbath == idx_checkbed):\n",
    "    print(\"Both list are same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it swaps the values of subsets of bathrooms and bedrooms \n",
    "df.loc[idx_checkbath,['bathrooms','bedrooms']] = df.loc[idx_checkbath,['bedrooms','bathrooms']].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets check if the values has been changed\n",
    "df['checkbed'] = df['bedrooms'].apply(lambda value: value.startswith(' Number of bathrooms'))\n",
    "len(df[df[\"checkbed\"] == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subset of bathroom and bedroom that was interchanged has been updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the consistency of the area.sqft_living/sqft_lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the following code checks if all the values in the colummn start with sqft living\n",
    "df['check_sqftliving'] = df['area.sqft_living/sqft_lot'].apply(lambda value: value.startswith('sqft_living'))\n",
    "\n",
    "\n",
    "df[ df['check_sqftliving'] == False ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see that the column is consistent and ready to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the following code splits the colums into two column with \"=\" and later splits the area \n",
    "# column into sqft_living and sqft_lot\n",
    "df = df.join(df['area.sqft_living/sqft_lot'].str.split('=', 1, expand=True).rename(columns={0:'Reduntant', 1:'Area'}))\n",
    "\n",
    "df = df.join(df['Area'].str.split('\\\\', 1, expand=True).rename(columns={0:'sqft_living', 1:'sqft_lot'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets have a look into the dataframe and then delete the reduntant columns\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column address, room, area, area.sqft_living/sqft_lot has been split and is no longer required.\n",
    "\n",
    "The other column which were introduced to check the consistency are no longer required and hence should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df['address']\n",
    "del df['area.sqft_living/sqft_lot']\n",
    "del df['Reduntant']\n",
    "del df['check_sqftliving']\n",
    "del df[\"Area\"]\n",
    "del df[\"rooms\"]\n",
    "del df['checkbed']\n",
    "del df['checkbath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now extracting only the numbers out of the bedrooms and bathrooms column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reg exp has been taken from https://stackoverflow.com/questions/12475704/regular-expression-to-allow-only-integer-and-decimal\n",
    "df['bedrooms'] = df['bedrooms'].str.extract(r\"Number of bedrooms:\\s(\\d*[.]?\\d*$)\" , expand = True)\n",
    "\n",
    "df['bathrooms'] = df['bathrooms'].str.extract(r\"Number of bathrooms:\\s(\\d*[.]?\\d*$)\" , expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now , Let's rename and rearrange the columns according to the given requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rename(columns = {'area.sqft_above':'sqft_above', 'area.sqft_basement':'sqft_basement'}, inplace = True)\n",
    "\n",
    "df = df.reindex(columns =['date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', \n",
    "                            'view', 'condition', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'street', \n",
    "                            'city', 'statezip', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the data types of all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking into the datatype of the column following column's datatypes should be changed.\n",
    "\n",
    "1. **date** : should be changed to datetime64\n",
    "\n",
    "2. **bedrooms , sqft_living, sqft_lot** : should be changed to int64\n",
    "\n",
    "3. **bathroom**: should be changed to float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sqft_living'] = df['sqft_living'].astype('int64')\n",
    "df['sqft_lot'] = df['sqft_lot'].astype('int64')\n",
    "df['bedrooms'] = df['bedrooms'].astype('int64')\n",
    "df['bathrooms'] = df['bathrooms'].astype('float64')\n",
    "#df['street'] = df['street'].astype('string')\n",
    "#df['city'] = df['city'].astype('string')\n",
    "#df['street'] = df['street'].astype('string')\n",
    "#df['statezip'] = df['statezip'].astype('string')\n",
    "#df['country'] = df['country'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now changing the data type of date column to datetime64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['date'] = pd.to_datetime(df['date'], format=\"%Y%m%dT%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above commented code to change the datatype of date column gives an error of \"**day is out of range**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now define a function which validated the date and store the result in a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/16870663/how-do-i-validate-a-date-string-format-in-python\n",
    "# the following code defines a function to validatge the date\n",
    "import datetime \n",
    "def validate(date_text):\n",
    "    result = None\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_text, \"%Y%m%dT%H%M%S\")\n",
    "        result = 'NoError'\n",
    "    except ValueError:\n",
    "        result = 'Error'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del df['DateCheck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the following code applies the validate function on every value of \n",
    "#date column and store the  value in DateCheck column\n",
    "df['DateCheck'] = df['date'].apply(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gives the date with error\n",
    "df[df['DateCheck'] == 'Error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see that the first error date has the value of 31 days for the month of june, which is not possible. This error should be a data entry error which would have occured either pressing 6 instead of 5 or 7, or this would have occurred entering 31 instead of 30. Lets assume the latter to be true , and we will update this date to 20140630T000000.\n",
    "\n",
    "The second error date is due to the format issue, we will change it to the correct format matching with the other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting the index of the improper date values\n",
    "df[df['DateCheck'] == 'Error'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# updating the dates\n",
    "df = df.set_value(4334, 'date', '20140630T000000')\n",
    "df = df.set_value(4335, 'date', '20140523T000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# deleting the check column\n",
    "del df['DateCheck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing all the unnecessary spaces from the string columns\n",
    "df['country'] = df['country'].str.strip()\n",
    "df['statezip'] = df['statezip'].str.strip()\n",
    "df['city'] = df['city'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now convberting the date column to datetime data type\n",
    "df['date'] = pd.to_datetime(df['date'], format= \"%Y%m%dT%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleansing the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looking into the summary stats of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information above, we found `yr_renovated` is the only column with missing values, which in fact can be possible because there would be some houses which has not been renovated at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at summary statistics of numeric data\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information above tell us the following: \n",
    "\n",
    "- `price` has the minimum value of zero. This looks suispicious and should be checked.\n",
    "\n",
    "- `floors` is ranged from 1 to 3.5.\n",
    "\n",
    "- `bathrooms` is ranged from 0 to 8. We need to check and  to make sure this column only contains numbers with `.0`, `.25`, `.5`, and `.75`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Befor beginning with the data cleansing process , lets first check the duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.duplicated(keep = False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are two records with exacly the same information , with same price and same date. The record could be possible but looks suspicious as the same property cannot be sold more than once on a single day. Thus we assume that the second record is duplicate, and therefore we remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing the record at 4337 index\n",
    "df.drop(4337, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start looking into the column one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Inspeting **Country** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['country'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"country\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There looks no issue in the country column as all the records are from USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Inspecting **Statezip** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"statezip\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " sorted(df['statezip'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that all the values start WA followed by Zipcode. On searching the google we fould that all the zipcodes in the data are from WA(Washington) Reference: http://www.zipcodestogo.com/Washington/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Inspecting **City** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"city\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(df['city'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://en.wikipedia.org/wiki/List_of_cities_in_Washington#List_of_cities\n",
    "\n",
    "From the above output and making a google search we found the following errors/typos in the city column:\n",
    "\n",
    "InCorrect City Name| Correct City Name\n",
    "---------------|------------\n",
    "Auburnt, auburn | Auburn\n",
    "Belleview,Bellvue | Bellevue\n",
    "Coronation|Carnation\n",
    "Issaguah | Issaquah\n",
    "Kirkllund | Kirkland\n",
    "redmond,Redmonde,Redmund|Redmond\n",
    "Samamish, sammamish |Sammamish\n",
    "Seaattle, Seatle, seattlen|Seattle\n",
    "Snogualmie | Snoqualmie\n",
    "Woodenville | Woodinville|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace all incorrect cities with the correct name\n",
    "\n",
    "df.replace({\n",
    "        'Auburnt':'Auburn',\n",
    "        'auburn':'Auburn',\n",
    "        'Belleview':'Bellevue',\n",
    "        'Bellvue':'Bellevue',\n",
    "        'Coronation': 'Carnation',\n",
    "        'Issaguah':'Issaquah',\n",
    "        'Kirklund':'Kirkland',\n",
    "        'Redmonde':'Redmond',\n",
    "        'Redmund':'Redmond',\n",
    "        'redmond':'Redmond',\n",
    "        'Samamish':'Sammamish',\n",
    "        'sammamish':'Sammamish',\n",
    "        'Seaattle':'Seattle',\n",
    "        'Seatle':'Seattle',\n",
    "        'seattle':'Seattle',\n",
    "        'Snogualmie':'Snoqualmie',\n",
    "        'Sureline':'Shoreline',\n",
    "        'Woodenville':'Woodinville'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[ df['city'] == 'auburn' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inconsistencies and the typos has been fixed in the city column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Investigating **Street** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['street'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4525 unique values out of 4600. It could be because of the same street can be present in different cities and there is also a possiility of one property to be sold more than once. Lets check for the duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.duplicated(['street','statezip','yr_built','bedrooms','bathrooms','sqft_living','sqft_lot'], keep = False)].sort_values('street')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output we can see that the inspite of having same address and same other information  the properties differ in  price and date. It is infact possible that the same property cna be sold multiple times on different day with different price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Investigating **Year renovated** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['yr_renovated'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many missing values ,because of the fact that the house may not have been renovated at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Investigating **Yr built** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['yr_built'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks fine with the yr_built column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the integrity constraint of the yr_built and yr_renovated\n",
    "A property cannot be renovated before it is built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[ df['yr_renovated'] < df['yr_built'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four records which violates the rule, possible reason could be the yr_built and yr_renovated values has been interchasnged. Lets change the values to correct year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id = df[ df['yr_renovated'] < df['yr_built'] ].index.tolist()\n",
    "\n",
    "df.loc[id,['yr_renovated','yr_built']] = df.loc[id,['yr_built','yr_renovated']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[ df['yr_renovated'] < df['yr_built'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The yr_built and yr_renovated integrity has been resolved and updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Investigating **View, Waterfront Floors and Condition** columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted( df['floors'].unique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['floors'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks everything fine with the floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted( df['waterfront'].unique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['waterfront'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks everything fine with the waterfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted( df['view'].unique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['view'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks everything fine with the view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted( df['condition'].unique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks everything fine with the condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Investigating **Bedrooms and Bathrooms** columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted( df['bedrooms'].unique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['bedrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 records with `0` bathrooms. Will check this again after investigating bedrooms column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['bedrooms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted( df['bathrooms'].unique() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of bathrooms such as 1.05,2.3,2.55,2.57, etc are unaccepatable and should be rounded to nearest quarter.\n",
    "There are few values with 0. Lets check them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['bathrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two records of bathrooms with 0 values , will check them after converting all the values in the columm to the nearest quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ref:https://stackoverflow.com/questions/8118679/python-rounding-by-quarter-intervals\n",
    "#the function round off a number to a nearest quarter\n",
    "def roundPartial (value):\n",
    "    return round (value / 0.25) * 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['bathrooms'] = df['bathrooms'].apply(roundPartial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['bathrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the bathrooms has been rounded off to the nearest quarter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two cases where bathooms are 0 and two cases where bedrooms are 0.Lets check them if both of them occur tegether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[ (df['bedrooms'] == 0) & (df['bathrooms'] == 0) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we check online , the bathrooms and bedrooms are not available online ref:  https://www.redfin.com/WA/Seattle/814-E-Howe-St-98102/home/2089103 and https://www.redfin.com/WA/Redmond/20418-NE-64th-Pl-98053/home/446188\n",
    " , so we will let these values as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Investigating **sqft_above, sqft_basement, sqft_living, and  sqft_lot** columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two integrity rules should be met for these columns:\n",
    "\n",
    "1) Sqft_living = sqft_basement + sqft_above\n",
    "\n",
    "2) For a single floor building, sqft_lot > sqft_living"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the first integrity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['checksqft'] = ( df['sqft_living'] == df['sqft_basement'] + df['sqft_above'] )\n",
    "\n",
    "df[df['checksqft'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that there are two records which doesnot meet the first integrity rule, \n",
    "\n",
    "Updating  these two records using the following code, which updates sqf_living = sqft_basement + sqft_above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inde = df[df['checksqft'] == False].index.tolist()\n",
    "\n",
    "df.loc[inde,['sqft_living']] = df.loc[inde,['sqft_basement']].values + df.loc[inde,['sqft_above']].values \n",
    "\n",
    "#df[df['checksqft'] == False]\n",
    "del df['checksqft']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the second integrity rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a new df with all the records of one floor property\n",
    "df_floor = df[df['floors'] == 1]\n",
    "#checks the integrity condition\n",
    "df_floor['checklot'] = (df_floor['sqft_lot'] > df_floor['sqft_living'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_floor[df_floor['checklot'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one record which violates the second integrity rule. Possible reason could be that the values has been interchanged while updating. To correct this error we interchange the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id = df_floor[df_floor['checklot'] == False].index.tolist()\n",
    "id\n",
    "df.loc[id,['sqft_lot','sqft_living']] = df.loc[id,['sqft_living','sqft_lot']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value has been correctly updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting outliers in the sqft_above, sqft_living, sqft_basement, sqft_lot\n",
    "\n",
    "Getting summary stats of these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['sqft_above', 'sqft_basement', 'sqft_living', 'sqft_lot']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will investigate more about outliers by plotting boxplot of each colum. Lets start with the boxplot of sqft_above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb.boxplot(df['sqft_above'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqft_above_outliers = df[df.sqft_above > 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqft_above_outliers['floors'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 108 records whose sqft_above is greater than 4000.It could be possible because many of the records are more than one floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb.boxplot(df['sqft_lot'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqft_lot_outlier = df[ df['sqft_lot'] > 400000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqft_lot_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are possible 6 outliers, on checking with the internet(www.zillow.com) the rows at index 275,879,2480,3478 are correct as they match with the online source. The record at index 1078 is possibly correct as it contains a lot of address (16200- 16398).\n",
    "\n",
    "The record at index 1539 doesnot match with the online source, we will change its to value to the one mentioned on the internet(https://www.zillow.com/homedetails/18923-SE-416th-St-Enumclaw-WA-98022/48760188_zpid/) 2.16 acres which equals 94090 sqft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.set_value(1539, 'sqft_lot', 94090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb.boxplot(df['sqft_living'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqft_living_outlier = df[ df['sqft_living'] > 8000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqft_living_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 outliers , all of which has 5 or more bedrooms and bigger sqft_lot and 80% has 2 or more floors. So the data looks fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb.boxplot(df['sqft_basement'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[ df['sqft_basement'] > 4000 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On checking through the online sources the data looks fine, hence no error spotted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating **Price** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_null = df[df.price == 0]\n",
    "price_null.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use linear regression  to predict the price for there 248 cases and then impute the predicted price in the final data set.\n",
    "Use box plot to view outlier in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sb.boxplot(df['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the IQR\n",
    "#ref : http://stamfordresearch.com/outlier-removal-in-python-using-iqr-rule/\n",
    "\n",
    "q75, q25 = np.percentile(df.price[df['price'] > 0], [75 ,25])\n",
    "iqr = q75 - q25\n",
    " \n",
    "minprice = q25 - (iqr*1.5)\n",
    "maxprice = q75 + (iqr*1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining a new dataframe for the values of price greater than the\n",
    "# 3 quarterile range\n",
    "df_price = (df[df['price'] > maxprice]).sort_values('price', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting the records for the price greater than max price and the sqft_lot\n",
    "#less than 15000(mean of sqft lot) and sqft_living\n",
    "#less than mean of sqft living\n",
    "df_price[(df_price['sqft_lot'] < 15000) & (df_price['sqft_living'] < 2200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have got 10 records as a potential outlier, Lets check first five of them with the online sources(www.zillow.com):\n",
    "\n",
    "index|Our price| online price | WrongValue\n",
    "-----|---------|-------------|------\n",
    "4351| 26590000 | 265900| Yes\n",
    "4347 | 12899000 | 490000|yes\n",
    "4349|2199900 | --- | Maybe, because The data we have contains around 12 houses, but online sources shows the price for one house which is around 245K, so either we should update the whole record including all the column or  will completly remove this record. We will completly remove the record  for simplification. \n",
    "4348|2110000|211000|Yes\n",
    "2767|1400000|1400000|No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.set_value(4351, 'price', 265900)\n",
    "df = df.set_value(4347, 'price', 490000)\n",
    "df = df.set_value(4348, 'price', 211000)\n",
    "df.drop(4349, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[4351]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prices has been updated  and now lets check the lower outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[(df['price'] < 330000) & (df['price'] != 0)].sort_values('price', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check the first five values and check with nline source:\n",
    "\n",
    "index|Our price| online price | WrongValue\n",
    "-----|---------|-------------|------\n",
    "4352| 7800 | 292000| Yes\n",
    "1219 | 80000 | 230000|yes\n",
    "1587|83000 | 83000 | N0 \n",
    "4346|84350|1150000(estimated between 2013 n 2015|Yes\n",
    "588|90000|247798|yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.set_value(4352, 'price', 292000)\n",
    "df = df.set_value(1219, 'price', 230000)\n",
    "df = df.set_value(4346, 'price', 1150000)\n",
    "df = df.set_value(588, 'price', 247798)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[1219]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The price has been modified. The next step is to impute the prices for the records for which the price is zero, using Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing prices using linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#price_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a copy of the data frame\n",
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a new column zip for the model \n",
    "df2['zip'] = df2['statezip'].str.extract(r\"^WA (\\d{5})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['zip'] = df2['zip'].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = df2.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that sqft_living and sqft_above has a good correlation with price and the bedrooms view and sqft basement has fair co relation with price. Lets built a model using thses variabes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#taking the columns for the linear model\n",
    "modl = df2[['sqft_living', 'sqft_above','bedrooms', 'view','sqft_basement','price']].copy()\n",
    "modl = modl[ modl['price'] != 0 ]\n",
    "modl = modl[ (modl['bedrooms'] != 0) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create linear regression model\n",
    "\n",
    "lm = LinearRegression()\n",
    "# Fit the model\n",
    "train_data = modl.iloc[:,:-1]\n",
    "train_label = modl['price']\n",
    "lm.fit(train_data,train_label)\n",
    "\n",
    "# Calculate the predictive score\n",
    "lm.score(train_data,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 55% variation in the dataset is explaied by the model. Lets try another model by converting few variables into categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting few variables into categories\n",
    "df2['zip'] = df['zip'].astype('category')\n",
    "df2['yr_built'] = df['yr_built'].astype('category')\n",
    "df2['bathrooms'] = df['bathrooms'].astype('category')\n",
    "df2['bedrooms'] = df['bedrooms'].astype('category')\n",
    "df2['condition'] = df['condition'].astype('category')\n",
    "df2['view'] = df['view'].astype('category')\n",
    "df2['waterfront'] = df['waterfront'].astype('category')\n",
    "df2['floors'] = df['floors'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#taking the columns for the linear model\n",
    "model1 = df2[['sqft_living', 'sqft_above', 'floors', 'bathrooms', \n",
    "              'bedrooms', 'condition', 'view','waterfront','yr_built','zip',\n",
    "              'price']].copy()\n",
    "model1 = model1[ model1['price'] != 0 ]\n",
    "model1 = model1[ (model1['bathrooms'] != 0) \n",
    "                  & (model1['bedrooms'] != 0) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create linear regression model\n",
    "\n",
    "lm = LinearRegression()\n",
    "# Fit the model\n",
    "train_data = model1.iloc[:,:-1]\n",
    "train_label = model1['price']\n",
    "lm.fit(train_data,train_label)\n",
    "\n",
    "# Calculate the predictive score\n",
    "lm.score(train_data,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model explains 60% variation in the data. So we will use the second model to impute the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imputing the price on the main dataframe\n",
    "df.loc[df['price'] == 0, 'price'] = lm.predict(df.loc[df['price'] == 0, ['sqft_living', 'sqft_above',\n",
    "                                                                         'floors', 'bathrooms','bedrooms', \n",
    "                                                                         'condition', 'view','waterfront',\n",
    "                                                                         'yr_built','zip']] )\n",
    "# Round the price to 1 decimal places\n",
    "df['price'] = df['price'].round(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df[\"price\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows the price data has been imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# deleting the column as it was not requird according to the task\n",
    "del df['zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting date to the given format\n",
    "df['date'] = df['date'].dt.strftime('%Y%m%dT%H%M%S')\n",
    "df2['yr_built'] = df['yr_built'].astype('int64')\n",
    "df2['bathrooms'] = df['bathrooms'].astype('float64')\n",
    "df2['bedrooms'] = df['bedrooms'].astype('int64')\n",
    "df2['condition'] = df['condition'].astype('int64')\n",
    "df2['view'] = df['view'].astype('int64')\n",
    "df2['waterfront'] = df['waterfront'].astype('int64')\n",
    "df2['floors'] = df['floors'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing the data frame to a csv file\n",
    "df.to_csv('ass2_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assesment assessed the skills to process the raw data, clean it, parse it, make a tabular structure and  create a csv file from it. Skills gained after completing this assesment are:\n",
    "\n",
    "* Getting familiar with reading and poarsing a JSON file into a dataframee.\n",
    "* Gaining a thorough knowledge to use pandas library for the data frame manipulation.\n",
    "* outlier detection with box blox using matplot and seaborn library.\n",
    "* Building a regression model to impute a int column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
